# text_emotion_model

# 프로젝트 개요 
본 프로젝트의 목표는 30만 건의 대규모 게임 리뷰 데이터를 분석하여, 각 리뷰의 텍스트가 담고 있는 감성을 '긍정', '중립', '부정' 세 가지 범주로 자동 분류하는 딥러닝 모델을 개발하는 것입니다. 이를 위해 체계적인 데이터 전처리, BiLSTM 기반의 모델 설계 및 학습, 그리고 다각적인 성능 평가를 순차적으로 수행했습니다.

# 데이터 전처리 (Data Preprocessing)
모델이 텍스트 데이터를 효과적으로 학습하기 위해, 원시(Raw) 데이터를 수치화하고 정규화하는 전처리 과정을 수행했습니다. 총 30만 건의 리뷰 데이터가 이 과정에 사용되었습니다.

# 데이터 로드 및 정제
데이터 로딩: CSV 파일 형태로 저장된 리뷰 데이터를 pandas 라이브러리를 사용하여 로드했습니다.

결측치 제거: 텍스트(content) 또는 레이블(label) 데이터가 누락된 행은 모델 학습에 불필요하므로 dropna() 메서드를 사용하여 모두 제거했습니다.

레이블 필터링: 본 프로젝트의 목표인 '부정(0)', '중립(1)', '긍정(2)' 이외의 값을 가진 데이터를 제외하여 분석 대상 데이터의 일관성을 확보했습니다.

# 텍스트 토큰화 (Tokenization)
토큰화 정의: 문장을 의미를 가진 가장 작은 단위인 토큰(Token), 즉 단어로 분리하는 과정입니다.

실행: TensorFlow Keras의 Tokenizer를 사용해 30만 건의 전체 리뷰 텍스트를 기반으로 단어 사전을 구축했습니다. 이 과정에서 각 단어는 고유한 정수 인덱스를 부여받습니다.

결과: 생성된 토크나이저는 이후 새로운 텍스트 데이터를 동일한 기준으로 수치화하는 데 재사용될 수 있도록 tokenizer.pkl 파일로 저장되었습니다.

# 시퀀스 변환 및 패딩 (Sequence Conversion & Padding)
시퀀스 변환: 토큰화된 단어들을 위에서 구축한 단어 사전의 정수 인덱스로 변환하여, 각 리뷰를 숫자의 배열(Sequence)로 만들었습니다.

패딩: 딥러닝 모델은 고정된 크기의 입력을 요구합니다. 따라서 모든 리뷰 시퀀스의 길이를 동일하게 맞춰주기 위해 패딩(Padding)을 적용했습니다.

maxlen=147: 모든 시퀀스의 길이를 147로 고정했습니다. 이는 데이터셋의 평균적인 문장 길이를 고려하여 설정된 값입니다.

padding='post': 문장 길이가 147보다 짧을 경우, 문장의 뒷부분에 0을 채워 길이를 맞췄습니다.

# 데이터셋 분리
모델을 학습시키기 위한 데이터와 모델의 성능을 객관적으로 평가하기 위한 데이터를 분리했습니다.

scikit-learn의 train_test_split을 사용하여 전체 데이터셋을 **훈련 데이터 (80%)**와 **검증 데이터 (20%)**로 분할했습니다. 이는 모델이 훈련 데이터에만 과적합되는 것을 방지하고 일반화 성능을 측정하는 데 필수적입니다.

# 모델 학습 (Model Training)
전처리가 완료된 데이터를 사용하여 텍스트의 맥락을 효과적으로 이해할 수 있는 BiLSTM 모델을 설계하고 학습시켰습니다.

# 모델 아키텍처
Embedding Layer: 단어를 64차원의 밀집 벡터로 변환하여 의미적 관계를 학습합니다.

Bidirectional LSTM Layer: 문장을 정방향과 역방향으로 모두 학습하여 문맥 의존성을 극대화합니다. 64개의 유닛을 사용했으며, 양방향 처리 결과 128차원의 특징 벡터를 출력합니다.

Dropout Layers: 훈련 시 각각 50%, 40%의 뉴런을 무작위로 비활성화하여 모델의 과적합을 방지하고 일반화 성능을 향상시킵니다.

Dense Layers: LSTM에서 추출된 특징을 바탕으로 최종 분류를 수행합니다. 활성화 함수로 ReLU와 Softmax를 사용하여 3개의 클래스('부정', '중립', '긍정')에 대한 각 확률을 출력합니다.

# 훈련 설정 및 최적화
컴파일:

Optimizer: Adam (learning rate: 0.0001, clipnorm: 1.0)을 사용하여 안정적인 학습을 진행했습니다.

Loss Function: 다중 클래스 분류에 적합한 sparse_categorical_crossentropy를 사용했습니다.

조기 종료 (Early Stopping):

검증 데이터의 손실(val_loss)이 3 에포크(epoch) 연속으로 개선되지 않으면 학습을 자동으로 중단시켜 불필요한 훈련을 막고 최적의 모델 가중치를 확보했습니다.

# 모델 정확도 및 성능 평가
모델 학습 완료 후, 훈련 데이터와 검증 데이터에 대한 성능을 다각도로 평가하여 모델의 신뢰도를 검증했습니다.

훈련 데이터 

![Image](https://github.com/user-attachments/assets/4f4bf020-8219-44b6-8dcb-55f978f23200)

검증 데이터

![Image](https://github.com/user-attachments/assets/6b816cb5-1eea-41f6-ace4-98847012ddb1) 

# 평가 지표
정확도 (Accuracy): 전체 예측 중 올바르게 예측된 비율.

정밀도 (Precision): 해당 클래스로 예측한 결과 중 실제 그 클래스인 비율.

재현율 (Recall): 실제 해당 클래스인 데이터 중 모델이 올바르게 예측한 비율.

F1-Score: 정밀도와 재현율의 조화 평균으로, 클래스 불균형이 있을 때 유용한 지표.

# 평가 결과
모델의 성능을 훈련 데이터셋과 검증 데이터셋에 대해 측정한 결과는 다음과 같습니다. (아래 수치는 실제 실행 결과에 따라 달라질 수 있습니다.)

훈련데이터 그래프 및 혼동행렬

![Image](https://github.com/user-attachments/assets/cd99fd62-c3e2-4f01-9576-e89618879cb5) | ![Image](https://github.com/user-attachments/assets/7721fd6b-a06e-49b4-8690-48485bd13e8f) 
---|---|

검증데이터 그래프 및 혼동행렬
![Image](https://github.com/user-attachments/assets/b2cb0d5b-7987-405e-91fe-238bff144a82) | ![Image](https://github.com/user-attachments/assets/0d168abe-9657-4daf-be6e-61e1c19696ea) 
---|---|


분석: 검증 데이터에서 약 69%의 정확도를 달성했으며, 각 클래스별 F1-Score 또한 준수한 성능을 보였습니다. 훈련 데이터와 검증 데이터의 성능 차이가 크지 않아, 모델이 과적합되지 않고 새로운 데이터에 대해서도 일반화 성능을 잘 유지하고 있음을 알 수 있습니다.

시각화: 혼동 행렬(Confusion Matrix)과 분류 리포트 막대그래프를 통해 모델이 각 클래스를 얼마나 잘 구별하는지, 어떤 클래스 간에 혼동이 발생하는지를 시각적으로 분석하여 성능을 직관적으로 파악했습니다.

# 5. 결론
본 프로젝트를 통해 30만 건의 대규모 리뷰 데이터를 성공적으로 전처리하고, BiLSTM 기반의 딥러닝 모델을 학습시켜 높은 수준의 감성 분류 성능을 달성했습니다. 체계적인 전처리 과정과 과적합 방지 기법(Dropout, Early Stopping)의 적용은 모델의 안정성과 일반화 성능을 확보하는 데 핵심적인 역할을 했습니다. 본 모델은 게임 리뷰 모니터링, 사용자 피드백 분석 등 다양한 분야에서 효과적으로 활용될 수 있을 것으로 기대됩니다.
